{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "PyTorch allows the creation of subclasses of `torch.utils.data.Dataset` that represent a collection of data. The `Dataset` class is an abstract class that requires the implementation of two methods: `__len__` and `__getitem__`. The `__len__` method returns the size of the dataset, and the `__getitem__` method returns a sample from the dataset given an index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset\n",
    "\n",
    "The MNIST dataset is a collection of 70,000 images of handwritten digits. Each image is a 28x28 grayscale image, and each pixel is represented by a value between 0 and 255. The dataset is split into a training set of 60,000 images and a test set of 10,000 images. The MNIST dataset is a popular dataset for getting started with deep learning and computer vision.\n",
    "\n",
    "The `torchvision` package provides a convenient way to download and use the MNIST dataset. The `torchvision.datasets` module contains a number of popular datasets, including MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMyDataset\u001b[39;00m(Dataset):\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    Template class for creating a dataset in PyTorch.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    '''\n",
    "    Template class for creating a dataset in PyTorch.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        # Initialize the dataset\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the size of the dataset\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return the sample at the given index\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlaquatra/miniconda3/envs/audio/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 7275917.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 40527164.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 5200547.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 11788693.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/MNIST/raw\n",
      "\n",
      "60000\n",
      "(<PIL.Image.Image image mode=L size=28x28 at 0x7F9C70B726E0>, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# Download the dataset\n",
    "train_dataset = MNIST(root=\"data/MNIST/\", train=True, download=True) \n",
    "\n",
    "# ! train_dataset is a Dataset object\n",
    "# ! we do not need to implement the subclass\n",
    "\n",
    "# Get the size of the dataset\n",
    "print(len(train_dataset)) # 60000\n",
    "\n",
    "# Get the sample at index 0\n",
    "sample = train_dataset[0]\n",
    "print(sample) \n",
    "# (<PIL.Image.Image image mode=L size=28x28 at 0x7F9C70B726E0>, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ITALIC: ITALian Intent Classification\n",
    "\n",
    "The ITALIC dataset is a collection of around 16,000 audio recordings of Italian sentences. Each sentence has an associated intent, which is a label that describes the purpose of the sentence. The dataset is available on [Zenodo](https://zenodo.org/records/8040649). The dataset is also available through the huggingface datasets library. There are different configurations of the dataset:\n",
    "- `massive`: recordings are split into `train`, `validation`, and `test` sets according to the [textual version](https://arxiv.org/abs/2106.03714) of the dataset.\n",
    "- `hard_noisy`: recordings are split into `train`, `validation`, and `test` sets according to the auto-annotated level of noise in the recordings (e.g., test set contains only recordings with high noise).\n",
    "- `hard_speaker`: recordings are split into `train`, `validation`, and `test` sets according to the speaker of the recording (e.g., test set contains only recordings from speakers not in the training set).\n",
    "\n",
    "The `datasets` module from the huggingface library provides a convenient way to download and use different datasets. The `datasets` module contains a number of popular datasets, including ITALIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset italic (/home/mlaquatra/.cache/huggingface/datasets/RiTA-nlp___italic/massive/1.0.0/652d7ebb794f960178edd72867252cdfe3a68ec16d372791d07bf789ed9a7609)\n",
      "100%|██████████| 3/3 [00:00<00:00, 543.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11514\n",
      "{'id': 1, 'age': 27, 'gender': 'male', 'region': 'abruzzo', 'nationality': 'italiana', 'lisp': 'nessuno', 'education': 'master', 'speaker_id': 72, 'environment': 'silent', 'device': 'phone', 'scenario': 'alarm', 'field': 'close', 'intent': 'alarm_set', 'utt': 'svegliami alle nove di mattina venerdì', 'audio': {'path': '/home/mlaquatra/.cache/huggingface/datasets/downloads/extracted/7f25fd6b6a74a983b3f0c3ea3ec3768f916c1fd6a84cd344bc1cedbd9249e698/zenodo_dataset/recordings/1.wav', 'array': array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), 'sampling_rate': 16000}}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Please be sure to use use_auth_token=True and to set the access token\n",
    "# using huggingface-cli login\n",
    "# or follow https://huggingface.co/docs/hub/security-tokens \n",
    "\n",
    "# configs \"hard_speaker\" and \"hard_noisy\" are also available (to substitute \"massive\")\n",
    "italic = load_dataset(\"RiTA-nlp/ITALIC\", \"massive\", use_auth_token=True) \n",
    "italic_train = italic[\"train\"]\n",
    "italic_valid = italic[\"validation\"]\n",
    "italic_test  = italic[\"test\"]\n",
    "\n",
    "# Get the size of the dataset\n",
    "print(len(italic_train)) # 12800\n",
    "\n",
    "# Get the sample at index 0\n",
    "sample = italic_train[0]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete MNIST Example\n",
    "\n",
    "The following cell contains a complete example of training and testing of a custom CNN on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 97.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training loss: 0.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:18<00:00, 100.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training loss: 0.069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:18<00:00, 102.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training loss: 0.051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:18<00:00, 101.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training loss: 0.042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 96.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training loss: 0.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 97.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Training loss: 0.031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 97.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Training loss: 0.026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:18<00:00, 101.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Training loss: 0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:18<00:00, 99.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Training loss: 0.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:18<00:00, 99.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Training loss: 0.019\n",
      "Accuracy: 0.99000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm # Progress bar\n",
    "\n",
    "# Create the dataset\n",
    "train_dataset = MNIST(root=\"data/MNIST/\", train=True, download=True, transform=ToTensor())\n",
    "test_dataset = MNIST(root=\"data/MNIST/\", train=False, download=True, transform=ToTensor())\n",
    "\n",
    "# we can implement a validation split, how?\n",
    "\n",
    "# Create the dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.linear1 = nn.Linear(in_features=32*7*7, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear1(x)\n",
    "        return x\n",
    "\n",
    "# Create the model\n",
    "model = MyModel()\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "# Define the scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "# Training loop\n",
    "model = model.train() # Set the model in training mode\n",
    "for epoch in range(10):\n",
    "    # Iterate over the batches\n",
    "    losses = []\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        # Get the input data\n",
    "        input_data = batch[0]\n",
    "        # Get the target data\n",
    "        target = batch[1]\n",
    "        # Forward pass\n",
    "        output = model(input_data)\n",
    "        # Loss computation\n",
    "        loss = loss_fn(output, target)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Parameters update\n",
    "        optimizer.step()\n",
    "        # Reset the gradients\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "    avg_training_loss = sum(losses) / len(losses)\n",
    "    print(f\"Epoch {epoch+1} - Training loss: {avg_training_loss:.3f}\")\n",
    "\n",
    "# Evaluation loop\n",
    "model = model.eval() # Set the model in evaluation mode\n",
    "\n",
    "predictions = []\n",
    "targets = []\n",
    "with torch.no_grad(): # Disable gradient computation\n",
    "    for batch in test_dataloader:\n",
    "        # Get the input data\n",
    "        input_data = batch[0]\n",
    "        # Get the target data\n",
    "        target = batch[1]\n",
    "        # Forward pass\n",
    "        output = model(input_data)\n",
    "        # Save the predictions\n",
    "        predictions.append(output)\n",
    "        # Save the targets\n",
    "        targets.append(target)\n",
    "\n",
    "# Concatenate the predictions\n",
    "predictions = torch.cat(predictions, dim=0)\n",
    "# Concatenate the targets\n",
    "targets = torch.cat(targets, dim=0)\n",
    "\n",
    "# Compute the accuracy\n",
    "accuracy = (predictions.argmax(dim=1) == targets).float().mean()\n",
    "print(f\"Accuracy: {accuracy:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}